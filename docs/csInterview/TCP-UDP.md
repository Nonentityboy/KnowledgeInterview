## 00: 讲一讲 UDP 的概念？
### 面向报文
UDP 是一个面向报文（报文可以理解为一段段的数据）的协议。意思就是 UDP 只是报文的搬运工，不会对报文进行任何拆分和拼接操作。

具体来说

* 在发送端，应用层将数据传递给传输层的 UDP 协议，UDP 只会给数据增加一个 UDP 头标识下是 UDP 协议，然后就传递给网络层了
* 在接收端，网络层将数据传递给传输层，UDP 只去除 IP 报文头就传递给应用层，不会任何拼接操作

### 不可靠性
* UDP 是`无连接`的，也就是说通信不需要建立和断开连接。
* UDP 也是`不可靠`的。协议收到什么数据就传递什么数据，并且也不会备份数据，对方能不能收到是不关心的
* UDP `没有拥塞控制`，一直会以`恒定的速度发送数据`。即使网络条件不好，也不会对发送速率进行调整。这样实现的弊端就是在网络条件不好的情况下可能会导致丢包，但是优点也很明显，在某些实时性要求高的场景（比如电话会议）就需要使用 UDP 而不是 TCP。

### 高效
UDP 没有 TCP 那么复杂，需要保证数据不丢失且有序到达。所以 UDP 的头部开销小，只有八字节，相比 TCP 的至少二十字节要少得多，在传输数据报文时是很高效的。

![](https://s1.ax1x.com/2020/06/20/NljKjU.png)

头部包含了以下几个数据

* 两个十六位的端口号，分别为源端口（可选字段）和目标端口
* 整个数据报文的长度
* 整个数据报文的检验和（IPv4 可选 字段），该字段用于发现头部信息和数据中的错误


### 传输方式
UDP 不止支持`一对一`的传输方式，同样支持`一对多，多对多，多对一`的方式，也就是说 UDP 提供了`单播，多播，广播`的功能。

## 01: 讲讲TCP的概念？
### TCP 的头部

![](https://s1.ax1x.com/2020/06/20/NljRv8.png)
![](https://s1.ax1x.com/2020/06/20/NlzZ4A.jpg)
对于 TCP 头部来说，以下几个字段是很重要的

* `源端口、目标端口`如何标识唯一标识一个连接？答案是 TCP 连接的四元组——源 IP、源端口、目标 IP 和目标端口。 TCP 报文怎么没有源 IP 和目标 IP 呢？这是因为在 IP 层就已经处理了 IP 。TCP 只需要记录两者的端口即可。
* `序列号Sequence number`，这个序号保证了 TCP 传输的报文都是有序的，对端可以通过序号顺序的拼接报文，在 SYN 报文中交换彼此的初始序列号
* `确认号Acknowledgement Number`，这个序号表示数据接收端期望接收的下一个字节的编号是多少，同时也表示上一个序号的数据已经收到
* `窗口大小Window Size`，窗口大小，表示还能接收多少字节的数据，用于流量控制
* 标识符
  * URG=1：该字段为一表示本数据报的数据部分包含紧急信息，是一个高优先级数据报文，此时紧急指针有效。紧急数据一定位于当前数据包数据部分的最前面，紧急指针标明了紧急数据的尾部。
  * ACK=1：该字段为一表示确认号字段有效。此外，TCP 还规定在连接建立后传送的所有报文段都必须把 ACK 置为一。
  * PSH=1：该字段为一表示接收端应该立即将数据 push 给应用层，而不是等到缓冲区满后再提交。
  * RST=1：该字段为一表示当前 TCP 连接出现严重问题，可能需要重新建立 TCP 连接，也可以用于拒绝非法的报文段和拒绝连接请求。
  * SYN=1：当SYN=1，ACK=0时，表示当前报文段是一个连接请求报文。
  SYN=1，ACK=1时，表示当前报文段是一个同意建立连接的应答报文。
  * FIN=1：该字段为一表示此报文段是一个释放连接的请求报文


### 状态机
HTTP 是无连接的，所以作为下层的 TCP 协议也是无连接的，虽然看似 TCP 将两端连接了起来，但是其实只是两端共同维护了一个状态

![](https://yck-1254263422.cos.ap-shanghai.myqcloud.com/blog/2019-06-01-043743.png)

TCP 的状态机是很复杂的，并且与建立断开连接时的握手息息相关。

重要的性能指标 RTT：该指标表示发送端发送数据到接收到对端数据所需的往返时间。


## 02：讲讲TCP、UPD的区别？

### TCP、UPD基本区别：

* TCP是一个`面向连接的`、`可靠的`、`基于字节流`的传输协议。
* UDP是一个`面向无连接的`传输层协议。


### TCP三大核心特性

* 1. 面向连接（客户端与服务器的连接，双方互相通信之前）
  * TCP需要三次握手建立连接
  * UDP没有相应建立连接的过程。
* 2. 可靠性。TCP可靠性体现在
  * TCP 精准的记录了哪些数据发送，哪些数据被接受了，哪些没有被接收到，而且保证数据包按序列到达，不允许半点差错。这是`有状态`
  * 当意识到丢包或者网络环境不佳，TCP会根据具体情况调整自己的行为，控制自己的发送速度或者重发。这是`可控制`
  * 相应的，UDP是`无状态`，`不可控`的。
* 3. `面向字节流`。
  * UDP的数据传输是基于数据包的，这是因为仅仅继承了IP层特性，
  * TCP 为了维护状态，将一个个IP包变成了字节流。

## 03:  TCP 三次握手的过程？为什么是三次而不是两次、四次？

### 三次握手过程
![](https://s1.ax1x.com/2020/06/18/NnhsNn.jpg)

* 从最开始双方都处于CLOSED状态。然后服务端开始监听某个端口，进入了LISTEN状态。

* 然后客户端主动发起连接，发送 SYN , 自己变成了SYN-SENT状态。

* 服务端接收到，返回SYN和ACK(对应客户端发来的SYN)，自己变成了SYN-REVD。

* 之后客户端再发送ACK给服务端，自己变成了ESTABLISHED状态；服务端收到ACK之后，也变成了ESTABLISHED状态。

> SYN 是需要消耗一个序列号的，下次发送对应的 ACK 序列号要加1，为什么呢？只需要记住一个规则: 凡是需要对端确认的，一定消耗TCP报文的序列号。

SYN 需要对端的确认， 而 ACK 并不需要，因此 SYN 消耗一个序列号而 ACK 不需要。

### 为什么不是两次？
根本原因: 无法确认客户端的接收能力。

分析如下:

如果是两次，你现在发了 SYN 报文想握手，但是这个包滞留在了当前的网络中迟迟没有到达，TCP 以为这是丢了包，于是重传，两次握手建立好了连接。

看似没有问题，但是连接关闭后，如果这个滞留在网路中的包到达了服务端呢？这时候由于是两次握手，服务端只要接收到然后发送相应的数据包，就默认建立连接，但是现在客户端已经断开了。

这就带来了连接资源的浪费。

### 为什么不是四次？
三次握手的目的是确认双方发送和接收的能力，那四次握手可以嘛？

当然可以，100 次都可以。但为了解决问题，三次就足够了，再多用处就不大了

### 三次握手过程中可以携带数据么？
第三次握手的时候，可以携带。前两次握手不能携带数据。

如果前两次握手能够携带数据，那么一旦有人想攻击服务器，那么他只需要在第一次握手中的 SYN 报文中放大量数据，那么服务器势必会消耗更多的时间和内存空间去处理这些数据，增大了服务器被攻击的风险。

第三次握手的时候，客户端已经处于ESTABLISHED状态，并且已经能够确认服务器的接收、发送能力正常，这个时候相对安全了，可以携带数据。

## 04: 说说 TCP 四次挥手的过程？

### 四次挥手
![](https://s1.ax1x.com/2020/06/19/NnIRjf.jpg)

刚开始双方处于ESTABLISHED状态。

客户端要断开了，向服务器发送 FIN 报文，在 TCP 报文中的位置如下图:

![](https://s1.ax1x.com/2020/06/20/NlzZ4A.jpg)

发送后客户端变成了`FIN-WAIT-1`状态。注意, 这时候客户端同时也变成了`half-close(半关闭)`状态，即无法向服务端发送报文，只能接收。

服务端接收后向客户端确认，变成了`CLOSED-WAIT`状态。

客户端接收到了服务端的确认，变成了`FIN-WAIT2`状态。

随后，服务端向客户端发送FIN，自己进入`LAST-ACK`状态，

客户端收到服务端发来的FIN后，自己变成了`TIME-WAIT`状态，然后发送 ACK 给服务端。

注意了，这个时候，客户端需要等待足够长的时间，具体来说，是 `2 个 MSL(Maximum Segment Lifetime，报文最大生存时间)`, 在这段时间内如果客户端没有收到服务端的重发请求，那么表示 ACK 成功到达，挥手结束，否则客户端重发 ACK。

### 等待2MSL的意义

如果不等待会怎样？

如果不等待，客户端直接跑路，当服务端还有很多数据包要给客户端发，且还在路上的时候，若客户端的端口此时刚好被新的应用占用，那么就接收到了无用数据包，造成数据包混乱。所以，最保险的做法是`等服务器发来的数据包都死翘翘再启动新的应用`。

那，照这样说一个 MSL 不就不够了吗，为什么要等待 2 MSL?

* 1 个 MSL 确保四次挥手中主动关闭方最后的 ACK 报文最终能达到对端
* 1 个 MSL 确保对端没有收到 ACK 重传的 FIN 报文可以到达


这就是等待 2MSL 的意义。


### 为什么是四次挥手而不是三次？

因为服务端在接收到FIN, 往往不会立即返回FIN, 必须等到服务端所有的报文都发送完毕了，才能发FIN。因此先发一个ACK表示已经收到客户端的FIN，延迟一段时间才发FIN。这就造成了四次挥手。

如果是三次挥手会有什么问题？

等于说服务端将ACK和FIN的发送合并为一次挥手，这个时候长时间的延迟可能会导致客户端误以为FIN没有到达客户端，从而让客户端不断的重发FIN。

## 05：三次握手前，产生的半连接队列和 SYN Flood 攻击的关系？
三次握手前，服务端的状态从`CLOSED变为LISTEN`, 同时在内部创建了两个队列：`半连接队列`和`全连接队列`，即`SYN队列和ACCEPT队列`。

### 半连接队列
当客户端发送SYN到服务端，服务端收到以后回复ACK和SYN，状态由LISTEN变为SYN_RCVD，此时这个连接就被推入了SYN队列，也就是半连接队列。

### 全连接队列
当客户端返回ACK, 服务端接收后，三次握手完成。这个时候连接等待被具体的应用取走，在被取走之前，它会被推入另外一个 TCP 维护的队列，也就是全连接队列(Accept Queue)。

### SYN Flood 攻击原理
SYN Flood 属于典型的 `DoS/DDoS` 攻击。其攻击的原理很简单，就是`用客户端在短时间内伪造大量不存在的 IP 地址`，并`向服务端疯狂发送SYN`。对于服务端而言，会产生两个危险的后果:

* 处理大量的SYN包并返回对应ACK, 势必有大量连接处于SYN_RCVD状态，从而占满整个半连接队列，无法处理正常的请求。

* 由于是不存在的 IP，服务端长时间收不到客户端的ACK，会导致服务端不断重发数据，直到耗尽服务端的资源。

### 应对 SYN Flood 攻击？
* 增加 SYN 连接，也就是增加半连接队列的容量。
* 减少 SYN + ACK 重试次数，避免大量的超时重发。
* 利用 SYN Cookie 技术，在服务端接收到SYN后不立即分配连接资源，而是根据这个SYN计算出一个Cookie，连同第二次握手回复给客户端，在客户端回复ACK的时候带上这个Cookie值，服务端验证 Cookie 合法之后才分配连接资源。


## 06：每次都三次握手是不是很麻烦？TCP 快速打开的原理(TFO)？

这个优化后的 TCP 握手流程，也就是 TCP 快速打开(TCP Fast Open, 即TFO)的原理。

优化的过程是这样的，还记得我们说 SYN Flood 攻击时提到的 SYN Cookie 吗？这个 Cookie 可不是浏览器的Cookie, 用它同样可以实现 TFO。

### TFO 流程

#### 首轮三次握手
首先客户端发送SYN给服务端，服务端接收到。

注意哦！现在服务端不是立刻回复 SYN + ACK，而是通过计算得到一个SYN Cookie, 将这个Cookie放到 TCP 报文的 Fast Open选项中，然后才给客户端返回。

客户端拿到这个 Cookie 的值缓存下来。后面正常完成三次握手。

首轮三次握手就是这样的流程。而后面的三次握手就不一样啦！

#### 后面的三次握手
在后面的三次握手中，客户端会将之前缓存的 Cookie、SYN 和HTTP请求(是的，你没看错)发送给服务端，服务端验证了 Cookie 的合法性，如果不合法直接丢弃；如果是合法的，那么就正常返回SYN + ACK。

重点来了，现在服务端能向客户端发 HTTP 响应了！这是最显著的改变，三次握手还没建立，仅仅验证了 Cookie 的合法性，就可以返回 HTTP 响应了。

当然，客户端的ACK还得正常传过来，不然怎么叫三次握手。

![](https://s1.ax1x.com/2020/06/20/N1CSaD.jpg)

> 客户端最后握手的 ACK 不一定要等到服务端的 HTTP 响应到达才发送，两个过程没有任何关系。

### TFO 的优势
TFO 的优势并不在与首轮三次握手，而在于后面的握手，在拿到客户端的 Cookie 并验证通过以后，可以直接返回 HTTP 响应，充分利用了1 个RTT(Round-Trip Time，往返时延)的时间提前进行数据传输，积累起来还是一个比较大的优势。


## 07：讲一讲超时重传机制？ ARQ 协议？

ARQ 协议也就是`超时重传机制`。通过确认和超时机制保证了数据的正确送达，ARQ 协议包含停止等待 ARQ 和连续 ARQ


### 正常传输过程

只要 A 向 B 发送一段报文，都要停止发送并启动一个定时器，等待对端回应，在定时器时间内接收到对端应答就取消定时器并发送下一段报文。

### 报文丢失或出错

在报文传输的过程中可能会出现丢包。这时候超过定时器设定的时间就会再次发送丢包的数据直到对端响应，所以需要每次都备份发送的数据。

即使报文正常的传输到对端，也可能出现在传输过程中报文出错的问题。这时候对端会抛弃该报文并等待 A 端重传。

PS：一般定时器设定的时间都会大于一个 RTT 的平均时间。

### ACK 超时或丢失

对端传输的应答也可能出现丢失或超时的情况。那么超过定时器时间 A 端照样会重传报文。这时候 B 端收到相同序号的报文会丢弃该报文并重传应答，直到 A 端发送下一个序号的报文。

在超时的情况下也可能出现应答很迟到达，这时 A 端会判断该序号是否已经接收过，如果接收过只需要丢弃应答即可。

这个协议的缺点就是传输效率低，在良好的网络环境下每次发送报文都得等待对端的 ACK 。

### 连续 ARQ
在连续 ARQ 中，发送端拥有一个发送窗口，可以在没有收到应答的情况下持续发送窗口内的数据，这样相比停止等待 ARQ 协议来说减少了等待时间，提高了效率。

### 累计确认
连续 ARQ 中，接收端会持续不断收到报文。如果和停止等待 ARQ 中接收一个报文就发送一个应答一样，就太浪费资源了。通过累计确认，可以在收到多个报文以后统一回复一个应答报文。报文中的 ACK 可以用来告诉发送端这个序号之前的数据已经全部接收到了，下次请发送这个序号 + 1的数据。

但是累计确认也有一个弊端。在连续接收报文时，可能会遇到接收到序号 5 的报文后，并未接到序号 6 的报文，然而序号 7 以后的报文已经接收。遇到这种情况时，ACK 只能回复 6，这样会造成发送端重复发送数据，这种情况下可以通过 Sack 来解决，这个会在下文说到。


## 08：说一说 TCP 的流量控制？

对于发送端和接收端而言，TCP 需要把发送的数据放到`发送缓存区`, 将接收的数据放到`接收缓存区`。

而流量控制索要做的事情，就是在通过接收缓存区的大小，控制发送端的发送。如果对方的接收缓存区满了，就不能再继续发送了。

要具体理解流量控制，首先需要了解`滑动窗口`的概念。

### TCP 滑动窗口

TCP 滑动窗口分为两种: `发送窗口`和`接收窗口`


#### 发送窗口
发送端的滑动窗口结构如下:

![](https://s1.ax1x.com/2020/06/21/N1nBqJ.jpg)

其中包含四大部分:

* 已发送且已确认
* 已发送但未确认
* 未发送但可以发送
* 未发送也不可以发送

其中有一些重要的概念，我标注在图中: 

![](https://s1.ax1x.com/2020/06/21/N1ngG6.jpg)

发送窗口就是图中被框住的范围。SND 即send, WND 即window, UNA 即unacknowledged, 表示未被确认，NXT 即next, 表示下一个发送的位置。


#### 接收窗口
接收端的窗口结构如下:
![](https://s1.ax1x.com/2020/06/21/N1ngG6.jpg)

REV 即 `receive`，NXT 表示下一个接收的位置，`WND` 表示接收窗口大小。

### 流量控制过程

滑动窗口实现了流量控制。接收方通过报文告知发送方还可以发送多少数据，从而保证接收方能够来得及接收数据。

## 09：能不能说说 TCP 的拥塞控制？
上一节所说的流量控制发生在发送端跟接收端之间，并没有考虑到整个网络环境的影响，如果说当前网络特别差，特别容易丢包，那么发送端就应该注意一些了。而这，也正是拥塞控制需要处理的问题。

对于拥塞控制来说，TCP 每条连接都需要维护两个核心状态:

* 拥塞窗口（Congestion Window，cwnd）
* 慢启动阈值（Slow Start Threshold，ssthresh）


涉及到的算法有这几个:

* 慢启动
* 拥塞避免
* 快速重传
* 快速恢复

接下来，我们就来一一拆解这些状态和算法。首先，从拥塞窗口说起。

### 拥塞窗口

拥塞窗口（Congestion Window，cwnd）是指目前自己还能传输的数据量大小。

那么之前介绍了接收窗口的概念，两者有什么区别呢？

* 接收窗口(rwnd)是接收端给的限制
* 拥塞窗口(cwnd)是发送端的限制


限制谁呢？

限制的是发送窗口的大小。

有了这两个窗口，如何来计算发送窗口？

发送窗口大小 = min(rwnd, cwnd)
取两者的较小值。而拥塞控制，就是来控制cwnd的变化。

### 慢启动
刚开始进入传输数据的时候，你是不知道现在的网路到底是稳定还是拥堵的，如果做的太激进，发包太急，那么疯狂丢包，造成雪崩式的网络灾难。

因此，拥塞控制首先就是要采用一种保守的算法来慢慢地适应整个网路，这种算法叫慢启动。运作过程如下:

* 首先，三次握手，双方宣告自己的接收窗口大小
* 双方初始化自己的拥塞窗口(cwnd)大小
* 在开始传输的一段时间，发送端每收到一个 ACK，拥塞窗口大小加 1，也就是说，每经过一个 RTT，cwnd 翻倍。如果说初始窗口为 10，那么第一轮 10 个报文传完且发送端收到 ACK 后，cwnd 变为 20，第二轮变为 40，第三轮变为 80，依次类推。
* 难道就这么无止境地翻倍下去？当然不可能。它的阈值叫做慢启动阈值，当 cwnd 到达这个阈值之后，好比踩了下刹车，别涨了那么快了，老铁，先 hold 住！

在到达阈值后，如何来控制 cwnd 的大小呢？

这就是拥塞避免做的事情了。

### 拥塞避免
原来每收到一个 ACK，cwnd 加1，现在到达阈值了，cwnd 只能加这么一点: 1 / cwnd。那你仔细算算，一轮 RTT 下来，收到 cwnd 个 ACK, 那最后拥塞窗口的大小 cwnd 总共才增加 1。

也就是说，以前一个 RTT 下来，cwnd翻倍，现在cwnd只是增加 1 而已。

当然，慢启动和拥塞避免是一起作用的，是一体的。

### 快速重传
在 TCP 传输的过程中，如果发生了丢包，即接收端发现数据段不是按序到达的时候，接收端的处理是重复发送之前的 ACK。

比如第 5 个包丢了，即使第 6、7 个包到达的接收端，接收端也一律返回第 4 个包的 ACK。当发送端收到 3 个重复的 ACK 时，意识到丢包了，于是马上进行重传，不用等到一个 RTO 的时间到了才重传。

这就是快速重传，它解决的是是否需要重传的问题。

#### 选择性重传
那你可能会问了，既然要重传，那么只重传第 5 个包还是第5、6、7 个包都重传呢？

当然第 6、7 个都已经到达了，TCP 的设计者也不傻，已经传过去干嘛还要传？干脆记录一下哪些包到了，哪些没到，针对性地重传。

在收到发送端的报文后，接收端回复一个 ACK 报文，那么在这个报文首部的可选项中，就可以加上SACK这个属性，通过left edge和right edge告知发送端已经收到了哪些区间的数据报。因此，即使第 5 个包丢包了，当收到第 6、7 个包之后，接收端依然会告诉发送端，这两个包到了。剩下第 5 个包没到，就重传这个包。这个过程也叫做选择性重传(SACK，Selective Acknowledgment)，它解决的是如何重传的问题。

### 快速恢复
当然，发送端收到三次重复 ACK 之后，发现丢包，觉得现在的网络已经有些拥塞了，自己会进入快速恢复阶段。

在这个阶段，发送端如下改变：

* 拥塞阈值降低为 cwnd 的一半
* cwnd 的大小变为拥塞阈值
* cwnd 线性增加


以上就是 TCP 拥塞控制的经典算法: 慢启动、拥塞避免、快速重传和快速恢复。


## 10: 假如发送端不停地给接收端发很小的包，Nagle 算法和延迟确认？

### Nagle 算法
试想一个场景，发送端不停地给接收端发很小的包，一次只发 1 个字节，那么发 1 千个字节需要发 1000 次。这种频繁的发送是存在问题的，不光是传输的时延消耗，发送和确认本身也是需要耗时的，频繁的发送接收带来了巨大的时延。

而避免小包的频繁发送，这就是 Nagle 算法要做的事情。

具体来说，Nagle 算法的规则如下:

* 当第一次发送数据时不用等待，就算是 1byte 的小包也立即发送
* 后面发送满足下面条件之一就可以发了:
  * 数据包大小达到最大段大小(Max Segment Size, 即 MSS)
  * 之前所有包的 ACK 都已接收到


### 延迟确认
试想这样一个场景，当我收到了发送端的一个包，然后在极短的时间内又接收到了第二个包，那我是一个个地回复，还是稍微等一下，把两个包的 ACK 合并后一起回复呢？

延迟确认(delayed ack)所做的事情，就是后者，稍稍延迟，然后合并 ACK，最后才回复给发送端。TCP 要求这个延迟的时延必须小于500ms，一般操作系统实现都不会超过200ms。

不过需要主要的是，有一些场景是不能延迟确认的，收到了就要马上回复:

* 接收到了大于一个 frame 的报文，且需要调整窗口大小
* TCP 处于 quickack 模式（通过tcp_in_quickack_mode设置）
* 发现了乱序包


### 两者一起使用会怎样
前者意味着延迟发，后者意味着延迟接收，会造成更大的延迟，产生性能问题。

## 11：理解 TCP 的 keep-alive？

大家都听说过 http 的keep-alive, 不过 TCP 层面也是有keep-alive机制，而且跟应用层不太一样。

试想一个场景，当有一方因为网络故障或者宕机导致连接失效，由于 TCP 并不是一个轮询的协议，在下一个数据包到达之前，对端对连接失效的情况是一无所知的。

这个时候就出现了 keep-alive, 它的作用就是探测对端的连接有没有失效。

在 Linux 下，可以这样查看相关的配置:
```bash
sudo sysctl -a | grep keepalive

// 每隔 7200 s 检测一次
net.ipv4.tcp_keepalive_time = 7200
// 一次最多重传 9 个包
net.ipv4.tcp_keepalive_probes = 9
// 每个包的间隔重传间隔 75 s
net.ipv4.tcp_keepalive_intvl = 75
```

不过，现状是大部分的应用并没有默认开启 TCP 的keep-alive选项，为什么？

站在应用的角度:

* 7200s 也就是两个小时检测一次，时间太长
* 时间再短一些，也难以体现其设计的初衷, 即检测长时间的死连接


因此是一个比较尴尬的设计。